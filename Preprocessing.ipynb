{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGO 645 Final Project: Preprocessing\n",
    "\n",
    "By: Lalitha Guru Swaminathan, Mabel Heffring, Saroj Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Cleaning and Preparation\n",
    "\n",
    "### Step 1: Extract Raster Data for each Water Quality Station using QGIS\n",
    "Talk about it here (to be filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Cleaning and Preparing River Water Quality (WQ) Data\n",
    "\n",
    "- Selecting relevant values\n",
    "- Removing missing values\n",
    "- Checking column types and removing prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4909 entries, 0 to 4908\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                     Non-Null Count  Dtype         \n",
      "---  ------                                     --------------  -----         \n",
      " 0   StationNumber                              4909 non-null   object        \n",
      " 1   LatitudeDecimalDegrees                     4909 non-null   float64       \n",
      " 2   LongitudeDecimalDegrees                    4909 non-null   float64       \n",
      " 3   SampleDatetime                             4909 non-null   datetime64[ns]\n",
      " 4   RiverSubBasinCode                          4909 non-null   object        \n",
      " 5   100923 PH (FIELD) pH units                 4909 non-null   float64       \n",
      " 6   80558 OXYGEN DISSOLVED (FIELD METER) mg/L  4909 non-null   float64       \n",
      " 7   10602 HARDNESS TOTAL CACO3 (CALCD.) mg/L   4909 non-null   float64       \n",
      " 8   102647 NITROGEN NITRATE mg/L               4909 non-null   float64       \n",
      " 9   2014 PHOSPHATE DISSOLVED ORTHO mg/L        4909 non-null   float64       \n",
      " 10  2002 TURBIDITY NTU                         4909 non-null   float64       \n",
      " 11  100629 COLIFORMS FECAL No/100 mL           4909 non-null   float64       \n",
      " 12  2003 CHLORIDE DISSOLVED mg/L               4909 non-null   float64       \n",
      " 13  201 TOTAL DISSOLVED SOLIDS (CALCD.) mg/L   4909 non-null   float64       \n",
      " 14  100924 SPECIFIC CONDUCTANCE (FIELD) uS/cm  4909 non-null   float64       \n",
      " 15  106256 FLOW, ESTIMATE N/A                  4909 non-null   float64       \n",
      " 16  100925 TEMPERATURE WATER deg C             4909 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(14), object(2)\n",
      "memory usage: 652.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Importing WQ data for all 5 years\n",
    "wq2018_rivers = pd.read_csv(\"data/water_quality/2018_WQ_rivers.csv\")\n",
    "wq2019_rivers = pd.read_csv(\"data/water_quality/2019_WQ_rivers.csv\")\n",
    "wq2020_rivers = pd.read_csv(\"data/water_quality/2020_WQ_rivers.csv\")\n",
    "wq2021_rivers = pd.read_csv(\"data/water_quality/2021_WQ_rivers.csv\")\n",
    "wq2022_rivers = pd.read_csv(\"data/water_quality/2022_WQ_rivers.csv\")\n",
    "\n",
    "# Selecting relevant features\n",
    "relevant_features = ['StationNumber', 'LatitudeDecimalDegrees','LongitudeDecimalDegrees', 'SampleDatetime',\n",
    "                     'RiverSubBasinCode', '100923 PH (FIELD) pH units','80558 OXYGEN DISSOLVED (FIELD METER) mg/L',\n",
    "                     '10602 HARDNESS TOTAL CACO3 (CALCD.) mg/L','102647 NITROGEN NITRATE mg/L','2014 PHOSPHATE DISSOLVED ORTHO mg/L',\n",
    "                     '2002 TURBIDITY NTU','100629 COLIFORMS FECAL No/100 mL','2003 CHLORIDE DISSOLVED mg/L',\n",
    "                     '201 TOTAL DISSOLVED SOLIDS (CALCD.) mg/L',#'103949 LEAD DISSOLVED ug/L','103928 ARSENIC DISSOLVED ug/L',\n",
    "                     #'109749 MERCURY DISSOLVED ng/L',\n",
    "                     '100924 SPECIFIC CONDUCTANCE (FIELD) uS/cm','106256 FLOW, ESTIMATE N/A',\n",
    "                     #'97060 TEMPERATURE AIR deg C',\n",
    "                     '100925 TEMPERATURE WATER deg C']\n",
    "\n",
    "wq2018_rivers_cleaned = wq2018_rivers[relevant_features]\n",
    "wq2019_rivers_cleaned = wq2019_rivers[relevant_features]\n",
    "wq2020_rivers_cleaned = wq2020_rivers[relevant_features]\n",
    "wq2021_rivers_cleaned = wq2021_rivers[relevant_features]\n",
    "wq2022_rivers_cleaned = wq2022_rivers[relevant_features]\n",
    "\n",
    "# removing nan values\n",
    "wq2018_rivers_cleaned = wq2018_rivers_cleaned.dropna()\n",
    "wq2019_rivers_cleaned = wq2019_rivers_cleaned.dropna()\n",
    "wq2020_rivers_cleaned = wq2020_rivers_cleaned.dropna()\n",
    "wq2021_rivers_cleaned = wq2021_rivers_cleaned.dropna()\n",
    "wq2022_rivers_cleaned = wq2022_rivers_cleaned.dropna()\n",
    "\n",
    "# function to fix the data types and remove L and G prefix (standing for less than or greater than)\n",
    "def change_datatypes(data):\n",
    "    for column_name in data.columns:\n",
    "        if column_name not in ['StationNumber','SampleDatetime', 'RiverSubBasinCode']:\n",
    "            if data[column_name].dtype != float:\n",
    "                data[column_name] = data[column_name].replace({'L': '','G':''}, regex=True).astype(float)\n",
    "        elif column_name == 'SampleDatetime':\n",
    "            data[column_name] = pd.to_datetime(data[column_name])\n",
    "    return data\n",
    "\n",
    "wq2018_rivers_cleaned = change_datatypes(wq2018_rivers_cleaned)\n",
    "wq2019_rivers_cleaned = change_datatypes(wq2019_rivers_cleaned)\n",
    "wq2020_rivers_cleaned = change_datatypes(wq2020_rivers_cleaned)\n",
    "wq2021_rivers_cleaned = change_datatypes(wq2021_rivers_cleaned)\n",
    "wq2022_rivers_cleaned = change_datatypes(wq2022_rivers_cleaned)\n",
    "\n",
    "# combining water quality results for all 5 years\n",
    "wq_rivers = pd.concat([wq2018_rivers_cleaned, wq2019_rivers_cleaned, wq2020_rivers_cleaned, wq2021_rivers_cleaned, wq2022_rivers_cleaned], axis=0, ignore_index=True)\n",
    "\n",
    "# printing data frame information\n",
    "wq_rivers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Cleaning and Preparing Lake Water Quality (WQ) Data\n",
    "\n",
    "- Selecting relevant values\n",
    "- Removing missing values\n",
    "- Checking column types and removing prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14088 entries, 0 to 14087\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                     Non-Null Count  Dtype         \n",
      "---  ------                                     --------------  -----         \n",
      " 0   StationNumber                              14088 non-null  object        \n",
      " 1   LatitudeDecimalDegrees                     14088 non-null  float64       \n",
      " 2   LongitudeDecimalDegrees                    14088 non-null  float64       \n",
      " 3   SampleDatetime                             14088 non-null  datetime64[ns]\n",
      " 4   RiverSubBasinCode                          14088 non-null  object        \n",
      " 5   100923 PH (FIELD) pH units                 14088 non-null  float64       \n",
      " 6   80558 OXYGEN DISSOLVED (FIELD METER) mg/L  14088 non-null  float64       \n",
      " 7   100924 SPECIFIC CONDUCTANCE (FIELD) uS/cm  14088 non-null  float64       \n",
      " 8   100925 TEMPERATURE WATER deg C             14088 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), object(2)\n",
      "memory usage: 990.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Importing WQ data for all 5 years\n",
    "wq2018_lakes = pd.read_csv(\"data/water_quality/2018_WQ_lakes.csv\")\n",
    "wq2019_lakes = pd.read_csv(\"data/water_quality/2019_WQ_lakes.csv\")\n",
    "wq2020_lakes = pd.read_csv(\"data/water_quality/2020_WQ_lakes.csv\")\n",
    "wq2021_lakes = pd.read_csv(\"data/water_quality/2021_WQ_lakes.csv\")\n",
    "wq2022_lakes = pd.read_csv(\"data/water_quality/2022_WQ_lakes.csv\")\n",
    "\n",
    "# Selecting relevant features\n",
    "relevant_features = ['StationNumber', 'LatitudeDecimalDegrees','LongitudeDecimalDegrees', 'SampleDatetime',\n",
    "                     'RiverSubBasinCode', '100923 PH (FIELD) pH units','80558 OXYGEN DISSOLVED (FIELD METER) mg/L',\n",
    "                     '100924 SPECIFIC CONDUCTANCE (FIELD) uS/cm','100925 TEMPERATURE WATER deg C']\n",
    "\n",
    "wq2018_lakes_cleaned = wq2018_lakes[relevant_features]\n",
    "wq2019_lakes_cleaned = wq2019_lakes[relevant_features]\n",
    "wq2020_lakes_cleaned = wq2020_lakes[relevant_features]\n",
    "wq2021_lakes_cleaned = wq2021_lakes[relevant_features]\n",
    "wq2022_lakes_cleaned = wq2022_lakes[relevant_features]\n",
    "\n",
    "# removing nan values\n",
    "wq2018_lakes_cleaned = wq2018_lakes_cleaned.dropna()\n",
    "wq2019_lakes_cleaned = wq2019_lakes_cleaned.dropna()\n",
    "wq2020_lakes_cleaned = wq2020_lakes_cleaned.dropna()\n",
    "wq2021_lakes_cleaned = wq2021_lakes_cleaned.dropna()\n",
    "wq2022_lakes_cleaned = wq2022_lakes_cleaned.dropna()\n",
    "\n",
    "# fixing data types\n",
    "wq2018_lakes_cleaned = change_datatypes(wq2018_lakes_cleaned)\n",
    "wq2019_lakes_cleaned = change_datatypes(wq2019_lakes_cleaned)\n",
    "wq2020_lakes_cleaned = change_datatypes(wq2020_lakes_cleaned)\n",
    "wq2021_lakes_cleaned = change_datatypes(wq2021_lakes_cleaned)\n",
    "wq2022_lakes_cleaned = change_datatypes(wq2022_lakes_cleaned)\n",
    "\n",
    "# combining water quality results for all 5 years\n",
    "wq_lakes = pd.concat([wq2018_lakes_cleaned, wq2019_lakes_cleaned, wq2020_lakes_cleaned, wq2021_lakes_cleaned, wq2022_lakes_cleaned], axis=0, ignore_index=True)\n",
    "\n",
    "# printing data frame information\n",
    "wq_lakes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Cleaning and Preparing Climate Data\n",
    "- Selecting relevant values\n",
    "- Combining data for each month\n",
    "- Removing missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14036 entries, 0 to 15148\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Long     14036 non-null  float64\n",
      " 1   Lat      14036 non-null  float64\n",
      " 2   Clim_ID  14036 non-null  object \n",
      " 3   Tm       14036 non-null  float64\n",
      " 4   P        14036 non-null  float64\n",
      " 5   month    14036 non-null  int64  \n",
      " 6   year     14036 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 877.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# path to files\n",
    "dir = 'data/precipitation'\n",
    "\n",
    "# initiating data frame\n",
    "climate_data = pd.DataFrame()\n",
    "\n",
    "# months to loop through\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "# years to loop through\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Looping through each file and selecting relevant values\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        current_path = os.path.join(dir, 'en_climate_summaries_AB_' + m + '-' + y +'.csv')\n",
    "        current_data = pd.read_csv(current_path)\n",
    "\n",
    "        current_data_clean = current_data[['Long', 'Lat', 'Clim_ID', 'Tm', 'P']].copy()\n",
    "\n",
    "        current_data_clean['month'] = int(m)\n",
    "        current_data_clean['year'] = int(y)\n",
    "\n",
    "        climate_data = pd.concat([climate_data, current_data_clean], axis=0, ignore_index=True)\n",
    "\n",
    "# removing missing values\n",
    "climate_data = climate_data.dropna()\n",
    "\n",
    "# printing data frame information\n",
    "climate_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Cleaning and Preparing NDVI Data\n",
    "- Convert date column\n",
    "- remove missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135 entries, 0 to 134\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Week    135 non-null    datetime64[ns]\n",
      " 1   4810    135 non-null    float64       \n",
      " 2   4820    135 non-null    float64       \n",
      " 3   4830    135 non-null    float64       \n",
      " 4   4840    135 non-null    float64       \n",
      " 5   4841    135 non-null    float64       \n",
      " 6   4850    135 non-null    float64       \n",
      " 7   4860    135 non-null    float64       \n",
      " 8   4870    135 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(8)\n",
      "memory usage: 9.6 KB\n"
     ]
    }
   ],
   "source": [
    "# reading in the NDVI data\n",
    "ndvi_data = pd.read_csv(\"data/ndvi/NDVI.csv\")\n",
    "\n",
    "# converting date column to datetime\n",
    "ndvi_data['Week'] = pd.to_datetime(ndvi_data['Week'])\n",
    "\n",
    "# removing missing values\n",
    "ndvi_data = ndvi_data.dropna()\n",
    "\n",
    "# printing data type values\n",
    "ndvi_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Cleaning and Preparing Emission Data\n",
    "- Selecting relevant values\n",
    "- Combining data for each year\n",
    "- Removing missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 28971 entries, 0 to 29094\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   FacilityName  28971 non-null  object \n",
      " 1   RPLatitude    28971 non-null  float64\n",
      " 2   RPLongitude   28971 non-null  float64\n",
      " 3   year          28971 non-null  int64  \n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# path to files\n",
    "dir = 'data/release_points'\n",
    "\n",
    "# initiating data frame\n",
    "emission_data = pd.DataFrame()\n",
    "\n",
    "# years to loop through\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Looping through each file and selecting relevant values\n",
    "for y in years:\n",
    "    current_path = os.path.join(dir, y + '_release_points.csv')\n",
    "    with open(current_path, encoding='utf-8', errors='replace') as f:\n",
    "        current_data = pd.read_csv(f)\n",
    "\n",
    "        current_data_clean = current_data[['FacilityName', 'RPLatitude', 'RPLongitude']].copy()\n",
    "\n",
    "        current_data_clean['year'] = int(y)\n",
    "\n",
    "        emission_data = pd.concat([emission_data, current_data_clean], axis=0, ignore_index=True)\n",
    "\n",
    "# removing missing values\n",
    "emission_data = emission_data.dropna()\n",
    "\n",
    "# printing data frame information\n",
    "emission_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Cleaning and Preparing QGIS data\n",
    "- Selecting relevant values\n",
    "- Removing missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 209 entries, 4 to 431\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   StationNumber             209 non-null    object \n",
      " 1   LatititudeDecimalDegrees  209 non-null    float64\n",
      " 2   LongitudeDecimalDegrees   209 non-null    float64\n",
      " 3   AGG_ID                    209 non-null    int64  \n",
      " 4   Elevation                 209 non-null    float64\n",
      " 5   Slope                     209 non-null    float64\n",
      " 6   LC_1km                    209 non-null    float64\n",
      " 7   LC_5km                    209 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 14.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 191 entries, 2 to 428\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   StationNumber             191 non-null    object \n",
      " 1   LatititudeDecimalDegrees  191 non-null    float64\n",
      " 2   LongitudeDecimalDegrees   191 non-null    float64\n",
      " 3   AGG_ID                    191 non-null    int64  \n",
      " 4   Elevation                 191 non-null    float64\n",
      " 5   Slope                     191 non-null    float64\n",
      " 6   LC_1km                    191 non-null    float64\n",
      " 7   LC_5km                    191 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 13.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# reading in the NDVI data\n",
    "qgis_data = pd.read_csv(\"data/Station_Inventory_Filtered_w_dem_slope_LC_1km_5km.csv\")\n",
    "\n",
    "# dividing river and lake data\n",
    "qgis_data_rivers = qgis_data[qgis_data['StationType'] == '0 (RIVER OR STREAM)']\n",
    "qgis_data_lakes = qgis_data[qgis_data['StationType'] == '1 (LAKE)']\n",
    "\n",
    "# selecting relevant data\n",
    "qgis_data_rivers = qgis_data_rivers[['StationNumber', 'LatititudeDecimalDegrees', 'LongitudeDecimalDegrees', 'AGG_ID', 'Elevation', 'Slope', 'LC_1km', 'LC_5km']]\n",
    "qgis_data_lakes = qgis_data_lakes[['StationNumber', 'LatititudeDecimalDegrees', 'LongitudeDecimalDegrees', 'AGG_ID', 'Elevation', 'Slope', 'LC_1km', 'LC_5km']]\n",
    "\n",
    "# removing missing values\n",
    "qgis_data_rivers = qgis_data_rivers.dropna()\n",
    "qgis_data_lakes = qgis_data_lakes.dropna()\n",
    "\n",
    "# printing data type values\n",
    "qgis_data_rivers.info()\n",
    "qgis_data_lakes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

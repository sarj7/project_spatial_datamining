{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0788ad96-36f2-4f93-a62b-39d75eb28205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffa8920-48b3-490b-b232-d79735412efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Lalitha\\\\OneDrive\\\\Desktop\\\\project_spatial_datamining-main\\\\data\\\\cleaned\\\\wq_lakes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLalitha\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject_spatial_datamining-main\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwq_lakes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Lalitha\\\\OneDrive\\\\Desktop\\\\project_spatial_datamining-main\\\\data\\\\cleaned\\\\wq_lakes.csv'"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\Lalitha\\OneDrive\\Desktop\\project_spatial_datamining-main\\data\\cleaned\\wq_lakes.csv' \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580d4bb-725b-4099-9fc8-f90bf6b1100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bddcdba-60ce-4bf0-b0ba-89911da25ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_pca = [\n",
    "    '100923 PH (FIELD) pH units',\n",
    "    '80558 OXYGEN DISSOLVED (FIELD METER) mg/L',\n",
    "    '100924 SPECIFIC CONDUCTANCE (FIELD) uS/cm',\n",
    "    '100925 TEMPERATURE WATER deg C',\n",
    "    'Elevation',\n",
    "    'Slope',\n",
    "    'LC_1km',\n",
    "    'LC_5km',\n",
    "    'NDVI',\n",
    "    'Temperature',\n",
    "    'Precipitation',\n",
    "    'RP_count'\n",
    "]\n",
    "\n",
    "df_pca = df[columns_for_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a1022-feb3-4c5f-b38f-1cefaa814302",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9034b4-72c0-4038-81fb-8fa1f6316fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= None)\n",
    "pca_result = pca.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb30266-efbf-47af-bbde-29ae1f426795",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data=pca_result, columns=[f'PC{i+1}' for i in range(pca_result.shape[1])])\n",
    "\n",
    "# Show the PCA DataFrame\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f5a15-0a2d-4593-9947-33eac3ad2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afef02e-5123-46f9-b9b4-ada562137660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variance\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, color='blue')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.xticks(range(1, len(explained_variance) + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001be766-deaf-44c8-a428-95b7f31b58a2",
   "metadata": {},
   "source": [
    "We can neglect from PC5 since The higher the bar, the more significant the PC is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1ab0b-ee37-407e-897d-25de098f1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pca_df['PC1'], y=pca_df['PC2'])\n",
    "plt.title('PCA: First vs Second Principal Component')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c3c1f-03b3-49e1-9a63-1fcc48861218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the PCA loadings (eigenvectors)\n",
    "loadings = pca.components_[:2]  # Extract PC1 and PC2 loadings\n",
    "\n",
    "# Create a DataFrame with feature contributions\n",
    "loading_df = pd.DataFrame(loadings.T, index=columns_for_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Display the contributions of each feature\n",
    "print(loading_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0847c17-a392-4946-b20d-f65feeb9230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the third vs fourth principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=pca_df['PC3'], y=pca_df['PC4'])\n",
    "plt.title('PCA: Third vs Fourth Principal Component')\n",
    "plt.xlabel('PC3')\n",
    "plt.ylabel('PC4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094be81d-6aa0-4eb1-be03-72fd59efcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loading vectors for all principal components\n",
    "loadings = pd.DataFrame(pca.components_.T, \n",
    "                        columns=[f'PC{i+1}' for i in range(pca.n_components_)], \n",
    "                        index=columns_for_pca)\n",
    "\n",
    "# Display loadings for PC3 and PC4\n",
    "print(\"Feature Contributions to PC3 and PC4:\")\n",
    "print(loadings[['PC3', 'PC4']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b8a20-1a40-46c7-a540-a432ae3f3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  # For preventing overlap\n",
    "\n",
    "# Perform PCA (assuming df_scaled is your standardized dataset)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Get feature loadings (eigenvectors)\n",
    "loadings = pca.components_.T\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot of data points (optional)\n",
    "ax.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.2)\n",
    "\n",
    "# Add feature vectors\n",
    "feature_names = columns_for_pca  # List of column names used in PCA\n",
    "texts = []  # To store text labels for adjustment\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax.arrow(0, 0, loadings[i, 0], loadings[i, 1], \n",
    "             head_width=0.05, head_length=0.05, color='red')\n",
    "    text = ax.text(loadings[i, 0] * 1.1, loadings[i, 1] * 1.1, feature, \n",
    "                   color='black', fontsize=10)\n",
    "    texts.append(text)\n",
    "\n",
    "# Adjust text labels to prevent overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))\n",
    "\n",
    "# Labels and Title\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_title(\"PCA Biplot (Feature Loadings)\")\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2fa84-5620-4794-8292-235f540335eb",
   "metadata": {},
   "source": [
    "Inference: \n",
    "1. Significant variables from the dataset are: Dissolved Oxygen, Water temperature,specific conductance and elevation.\n",
    "2. More clusters in the centre, referring to few outliers.\n",
    "3. Temperature water and specific conductance seem to be positively correlated.\n",
    "4. Oxygen dissolved is in different direction, so negatively correlated with temperature water. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c210ba2-f384-4298-af76-8f05f8e27280",
   "metadata": {},
   "source": [
    "TRYING RANDOM FOREST REGRESSOR ON PC1 AND PC2 FEATURES OBTAINED FROM PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305f97b-9120-4cae-87f1-2c52209d088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "target = df['100923 PH (FIELD) pH units']  \n",
    "X_pca = pca_result[:, :2]  # PC1 and PC2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1a083-88cd-40af-ac39-b8529d2e2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on PCA-transformed data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81946c8-17c5-4f03-bf3d-208b20351c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027cb617-595a-4727-a41c-a94fd4cd8900",
   "metadata": {},
   "source": [
    "TRYING RANDOM FOREST REGRESSOR WITH ORIGINAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574207f-43f0-4085-b920-63370e2ef0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['100923 PH (FIELD) pH units'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361053c-1d2f-4ada-bc7b-4283be16e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['100923 PH (FIELD) pH units']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77073cef-2760-4479-8cc8-49aa3ca95fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfceae37-e36f-4823-bf39-48f052851f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985357a-3eab-4ea3-80c7-1b3529256329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with non-numeric values\n",
    "non_numeric_cols = df.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb87139-42b9-4208-98ba-061e6a53c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(columns=non_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3ed54-c6b1-4b72-afce-d1106c04fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "X_train['StationNumber'] = label_encoder.fit_transform(X_train['StationNumber'])\n",
    "X_train['RiverSubBasinCode'] = label_encoder.fit_transform(X_train['RiverSubBasinCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870af8e6-d976-4c97-bda8-93f6681ce44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=['StationNumber', 'RiverSubBasinCode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0243ad8-70c7-4f13-9c9a-f00f2f67d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime format\n",
    "X_train['SampleDatetime'] = pd.to_datetime(X_train['SampleDatetime'], errors='coerce')\n",
    "\n",
    "# Extract year, month, and day (or other time-based features as needed)\n",
    "X_train['Year'] = X_train['SampleDatetime'].dt.year\n",
    "X_train['Month'] = X_train['SampleDatetime'].dt.month\n",
    "X_train['Day'] = X_train['SampleDatetime'].dt.day\n",
    "X_train['Hour'] = X_train['SampleDatetime'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceab120-13bd-4e4b-86de-aab967a97779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea61f94-ef1d-4fcc-9b86-4280ad42bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'SampleDatetime' to datetime type\n",
    "X_train['SampleDatetime'] = pd.to_datetime(X_train['SampleDatetime'])\n",
    "\n",
    "# Extract year, month, day, hour, etc.\n",
    "X_train['Year'] = X_train['SampleDatetime'].dt.year\n",
    "X_train['Month'] = X_train['SampleDatetime'].dt.month\n",
    "X_train['Day'] = X_train['SampleDatetime'].dt.day\n",
    "X_train['Hour'] = X_train['SampleDatetime'].dt.hour\n",
    "\n",
    "# Drop the original 'SampleDatetime' column\n",
    "X_train = X_train.drop(columns=['SampleDatetime'])\n",
    "\n",
    "# Check the data types of the features\n",
    "print(X_train.dtypes)\n",
    "\n",
    "# Now you can train the model\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8e7b4-3711-4ed8-9f7a-a469efb8f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafe38a-7435-4053-b626-78a694b571bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align X_test columns with X_train\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "X_test = X_test.drop(columns=['SampleDatetime', 'StationNumber'], errors='ignore')\n",
    "\n",
    "# Re-train and predict\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02466052-6e9f-4e90-9bb1-a6af711cce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
